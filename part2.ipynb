{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b5a49df-c57a-4f72-9343-ad14253ce1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Tuple\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa77eea4-313e-4e78-8af0-e406fc03a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    data = pd.read_csv(\"./data/data.csv\").drop([\"Unnamed: 0\"], axis=1)\n",
    "    labels = pd.read_csv(\"./data/labels.csv\")[\"Class\"]\n",
    "        \n",
    "    # Encodes string labels as ints\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "    \n",
    "    return data.to_numpy(), y\n",
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841e1758-633a-4c7f-8794-9519de809f0b",
   "metadata": {},
   "source": [
    "# First feature reduction to reduce run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "345013f2-4673-4a36-9350-b687a61f21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "\n",
    "# Dropping the constant features\n",
    "X_nonconst = VarianceThreshold().fit_transform(X)\n",
    "\n",
    "# Doing feature selection by choosing the k features with the largest F-statistic\n",
    "k = 200\n",
    "X_fstat = SelectKBest(score_func=f_classif, k=k).fit_transform(X_nonconst, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57059f-0d55-4ac8-9b4c-e9df77cc03ee",
   "metadata": {},
   "source": [
    "# Feature selection using multi-class logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fdbff9d3-702c-4e3a-98f0-73eef12371ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "[[0.98148148 0.98148148 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [0.98148148 0.98148148 0.98148148 1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]]\n",
      "[[1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [0.98148148 1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [0.98113208 0.98113208 0.98113208 0.98113208 0.98113208 1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [0.98113208 1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]]\n",
      "[[1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [0.96296296 0.98148148 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]]\n",
      "[[0.96296296 0.96296296 0.96296296 0.98148148 0.98148148 0.98148148\n",
      "  0.98148148 0.98148148 0.98148148 0.98148148]\n",
      " [0.98148148 0.98148148 0.98148148 0.98148148 1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [0.88888889 0.96296296 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [0.98148148 1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [0.94339623 1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]\n",
      " [0.98113208 0.98113208 1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]]\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "n_folds = 10\n",
    "test_fraction = 0.33\n",
    "score_func = f1_score\n",
    "\n",
    "# Splits data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fstat, y, test_size=test_fraction)\n",
    "\n",
    "# Train model and extracts the best inverst regularisation parameter\n",
    "log_reg = LogisticRegressionCV(cv=n_folds,\n",
    "                               multi_class='ovr', \n",
    "                               solver='liblinear',\n",
    "                               intercept_scaling=10000).fit(X_train,y_train)\n",
    "c_min = log_reg.Cs\n",
    "print(type(log_reg.scores_))\n",
    "\n",
    "# Finds the C_1se for each label, i.e. the smalles C that produces\n",
    "# score within one std of the mean score for C_min for a given label\n",
    "c_1se = {}\n",
    "for key, val in log_reg.scores_.items():\n",
    "    print(val)\n",
    "    cv_mean = np.mean(val, axis=1)\n",
    "    cv_std = np.std(val, axis=1)\n",
    "    idx_min_mean = np.argmin(cv_mean)\n",
    "    idx_c = np.where(\n",
    "        (cv_mean <= cv_mean[idx_min_mean] + cv_std[idx_min_mean] / np.sqrt(n_folds)) &\n",
    "        (cv_mean >= cv_mean[idx_min_mean])\n",
    "    )[0][0]\n",
    "    c_1se[key] = val[idx_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9b54323-6a7a-4323-8398-8de348a09ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.98148148, 0.98148148, 0.98148148, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
       " 1: array([0.98148148, 0.98148148, 0.98148148, 0.98148148, 0.98148148,\n",
       "        0.98148148, 0.98148148, 0.98148148, 0.98148148, 0.98148148]),\n",
       " 2: array([0.96226415, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
       "        0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208]),\n",
       " 3: array([0.98148148, 0.98148148, 0.98148148, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
       " 4: array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_1se"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
